# 生成AIとベクトル検索を活かしたGoogle Drive検索システム (PoC: 概念実証版)

## はじめに
本ドキュメントは、「生成AIとベクトル検索を活用した次世代のGoogle Drive検索システム」の**概念実証（Proof of Concept）**を目的とする。

コンセプトの核となる価値（ヒット件数に応じたハイブリッド検索）を迅速に検証するため、実装範囲を**最小限の実行可能な構成（MVP: Minimum Viable Product）**に絞り込み、過剰な実装を避けた計画を定義する。

## セキュリティと権限に関する基本設計
* 本システムは、シングルユーザー環境での利用を前提とする。
* システム設計の核として、以下の権限モデルを採用する。
  *   **検索の起点**: ユーザーがCLIから実行する検索処理は、操作しているユーザー自身のGoogleアカウント認証情報を用いて開始される。
  *   **クロールの起点**: Google Drive クローラーも、検索処理と同一のユーザーのGoogleアカウント認証情報のみを用いて実行し、サービスアカウントなど別主体によるクロールは本PoCの想定外とする。
  *   **対象スコープの固定化**: PoCのクロール/検索対象は `.env` に記述した `GOOGLE_DRIVE_TARGET_FOLDER_IDS` で指定した各フォルダと、そのサブフォルダを再帰的にたどった配下のフォルダ／ファイルとする。

## 外部サービス構成
1.  **LLM / Embeddings**:
    *   推論用: GPT-4o mini
    *   ベクトル化用: text-embedding-3-small
2.  **DB**: Supabase
    *   拡張機能 `pgvector` を有効化
    * テーブル名: `drive_file_index`
      * カラム:
        * `file_id`: TEXT, PK
        * `file_name`: TEXT, NOT NULL
        * `summary`: TEXT, NOT NULL
        * `keywords`: TEXT[] (キーワード配列)
        * `embedding`: VECTOR, NOT NULL
        * `drive_modified_at`: TIMESTAMPTZ, NOT NULL (Google Drive の `modifiedTime` を保持)
        * `mime_type`: TEXT, NOT NULL
    * テーブル名: `drive_sync_state`
      * カラム:
        * `id`: TEXT, PK (例: `global` などシステム全体で1件のみ)
        * `drive_modified_at`: TIMESTAMPTZ, NOT NULL (クロールしたファイル群の最大 `modifiedTime` を保持)


## 実装内容

### 1. Google Drive クローラー (CLI / Cron)
Google Driveを定期的に巡回し、検索用インデックス（DB）を構築・更新する、システムの土台となる機能。

*   **プロセス**:
    0.  **ターゲットフォルダの解決**:
        *   `.env` の `GOOGLE_DRIVE_TARGET_FOLDER_IDS` を読み込み、Google Drive API で存在確認を行う。
            *   区切り文字 `,` で複数のターゲットフォルダを設定できる。
        *   フォルダが見つからない場合や権限が不足している場合は即座に失敗させ、誤ったスコープでクロールを開始しない。
    1.  **変更リストの取得（差分検出の効率化）**:
        *   初回のみ: `GOOGLE_DRIVE_TARGET_FOLDER_IDS` で指定した各フォルダを起点に、そのサブフォルダを再帰的にたどりながら `files.list` を用いて配下の全ファイルを取得し、各ファイルの `modifiedTime` を `drive_file_index.drive_modified_at` として保存する。
        *   初回以降: `drive_sync_state.drive_modified_at` 以降に更新されたファイルのみを対象に、同じくターゲットフォルダ配下（サブフォルダを含む階層全体）を再帰的にたどりながら `files.list` で取得し、差分クロールを行う。
            *   クエリ時点で、`GOOGLE_DRIVE_TARGET_FOLDER_IDS` で指定したフォルダと、そのサブフォルダを再帰的に列挙した範囲にスコープを限定する。
            *   Google Drive の仕様上、`modifiedTime` が変化しない削除・移動・権限変更はこの差分検出では拾えない。
        *   差分検出では「新規作成・更新」のみを追跡し、削除・移動・権限変更への追従は行わない。
    2.  **同期処理**:
        *   **新規・更新ファイル**: リスト内の新規・更新ファイルのうち、テキストコンテンツを取得可能なもののみを対象に、後述のAI処理を実行する。
        *   **削除・移動・権限変更**:
            *   `modifiedTime` ベースの差分検出では、Drive 上の削除・移動・権限変更を完全には検知できない。
            *   そのため PoC では、`drive_file_index` 上に「論理的には削除済み／移動済み／閲覧不可なファイル」のレコードが残り続ける「インデックスの汚れ」を仕様として許容する。
            *   製品化を見据えた将来バージョンでは、Drive の変更履歴 API や定期的なフルスキャンなどにより、インデックスのクリーンアップを行う想定とする。
    3.  **AI処理**:
        *   対象ファイルのテキストコンテンツを抽出。 *(注: GoogleドキュメントやPDF等のテキスト情報を主対象とし、画像ファイル内の文字列抽出（OCR）は今回の対象外とする。)*
        *   画像ファイルやその他バイナリファイル（例: `.jpg`, `.png`, `.gif`, `.zip` 等）はインデックス対象外とし、`drive_file_index` にレコードを作成しない（＝検索結果にも表示されない）。
        *   GPT-4o mini で「ファイル要約文」と「検索用キーワード」を生成。
        *   text-embedding-3-small で「要約文 + キーワード + ファイル名」を結合したテキストから「ベクトル（Embedding）」を生成。
    4.  **保存と状態更新**:
        *   AI処理後のすべての情報を Supabase の `drive_file_index` テーブルに Upsert（挿入・更新）する。
        *   次回のクロールに備え、取得したファイル群の最大 `modifiedTime` で `drive_sync_state.drive_modified_at` を更新する。

### 2. セマンティック検索プログラム (CLI)
CLIアプリケーションとして実装する。概念実証（PoC）の段階では、中核機能である「ヒット件数に応じたハイブリッド検索」が有効であることを証明するシンプルな構成とする。

*   **検索フロー**:
    1.  **クエリ解析 & 初期検索**:
        *   コマンドライン引数、または対話形式でユーザーの自然文クエリを受け付ける。
        *   クエリから日付指定があれば抽出し、期間フィルタ(`modifiedTime`)を用意する。
        *   クエリからファイル種別指定があれば抽出し、MIMEタイプフィルタ(`mimeType`)を用意する。
            *   現状はテキスト取得可能な MIME のみを対象とする。
        *   GPT-4o miniに対し、固有名詞、プロジェクト名、ファイル形式などを優先するよう指示したプロンプトを用いて、検索キーワードを3〜5件抽出させる。
        *   抽出した検索キーワードを元に、 Drive API を用いて `GOOGLE_DRIVE_TARGET_FOLDER_IDS` で指定した各フォルダを全文検索する。

    2.  **ヒット件数に応じた分岐ロジック**:
        *   ここでいう「ヒット件数」とは、まず Drive API で検索した結果集合と Supabase 上の `drive_file_index` に存在するファイルID集合との積集合を求め、その集合の件数（＝ユーザーに候補として提示可能なファイル数）を指す。
        *   ベクトル検索などでこの集合をさらに絞り込んだ場合は、その絞り込み後の集合の件数を次のループにおける「ヒット件数」として扱う。
        *   **ヒット件数が 101件以上 の場合 (対話によるキーワード絞り込み)**:
            *   「要約＋メタデータ」をコンテキストとして、ヒットした上位結果の傾向をGPT-4o miniに分析させ、絞り込むための「追加の質問」を生成し、コンソール上でユーザーに回答を求める。
            *   ユーザーのキーボード入力から「絞り込みに有効な追加キーワードを1件抽出する」または「フィルタ条件（期間・MIME）を追加する」ようGPT-4o miniに指示する。
            *   元のキーワードと追加キーワード or 追加フィルタを組み合わせ、再度 Google Drive API で全文検索を実行する。
        *   **ヒット件数が 11件 〜 100件 の場合 (ベクトル検索)**:
            *   text-embedding-3-small で「ユーザーのクエリ＋抽出キーワード」をベクトル化し、そのベクトルで drive_file_index.embedding に対して類似検索を行う。
                *   インデックス済みファイルのみを検索対象とする。
            *   Google Drive API でヒットしたファイル群のファイルID集合と `drive_file_index` のインデックス済みファイル集合との積集合をフィルターとして使用し、Supabase DB内でベクトル検索を実行する。
            *   これにより、「Drive検索結果 × インデックス」の積集合のうち、クエリとの関連性が高い候補（ヒット件数）を上位10件以下に絞り込む。
                *   絞り込み結果が 2件 〜 10件 ならば、次のループでリランキングが行われる想定。
        *   **ヒット件数が 2件 〜 10件 の場合 (LLMによるリランキング)**:
            *   取得したファイル情報をコンテキストとして GPT-4o mini に渡し、「ユーザーの質問意図に合致する順」にソートする。
            *   ソート後ファイル情報に基づき、ファイル名・要約文・Google Driveリンクを標準出力に一覧表示する。
        *   **ヒット件数が 1件 の場合 (そのまま表示)**:
            *   ヒット件数が 1件 の場合は、そのままファイル名・要約文・Google Driveリンクを標準出力に表示する。
        *   **ヒット件数が 0件 の場合 (キーワードの自動調整)**:
            *   検索キーワード数を減らす or フィルタ条件を緩和するようLLMに指示したうえで、再検索を実行し、検索ヒット件数を上げる。
            *   検索キーワードが1件になってもヒット件数が0件の場合は「見つかりませんでした」とコンソールに出力して終了する。
        *   上記分岐ロジックで「ヒット件数が 1件 〜 10件 の場合」または「検索キーワードが1件になってもヒット件数が0件の場合」は処理を終了。
            *   それ以外の場合は、同じ分岐処理を繰り返す。
        *   検索時、 LLM にコンテキストとして渡すファイル情報は、ユーザー自身の Drive 検索結果で得られた `file_id` の集合と Supabase 上のインデックス（`drive_file_index` テーブル）とを突き合わせたものに限定する。
